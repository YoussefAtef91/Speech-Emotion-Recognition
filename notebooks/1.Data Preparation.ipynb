{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install librosa seaborn kagglehub pyarrow fastparquet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import kagglehub\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/raw/emotional-speech-audio/1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"uwrfkaggler/ravdess-emotional-speech-audio\")\n",
    "\n",
    "destination_folder = \"../data/raw/emotional-speech-audio\"\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "shutil.move(path, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = glob(\"../data/raw/emotional-speech-audio/*/*/*.wav\")\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = []\n",
    "for filename in filenames:\n",
    "    modality = int(filename.split(\"/\")[6].split(\"-\")[0])\n",
    "    voice_channel = int(filename.split(\"/\")[6].split(\"-\")[1])\n",
    "    emotion = int(filename.split(\"/\")[6].split(\"-\")[2])\n",
    "    emontion_intensity = int(filename.split(\"/\")[6].split(\"-\")[3])\n",
    "    statement = int(filename.split(\"/\")[6].split(\"-\")[4])\n",
    "    repetition = int(filename.split(\"/\")[6].split(\"-\")[5])\n",
    "    actor = int(filename.split(\"/\")[6].split(\"-\")[5].split(\".\")[0])\n",
    "    gender = \"female\" if int(actor) % 2 == 0 else \"male\"\n",
    "    audio_features.append([filename, modality, voice_channel, emotion, emontion_intensity, statement, repetition, actor, gender])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"filename\", \"modality\", \"vocal_channel\", \"emotion\", \"emontion_intensity\", \"statement\", \"repetition\", \"actor\", \"gender\"]\n",
    "df = pd.DataFrame(audio_features, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>modality</th>\n",
       "      <th>vocal_channel</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emontion_intensity</th>\n",
       "      <th>statement</th>\n",
       "      <th>repetition</th>\n",
       "      <th>actor</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/raw/emotional-speech-audio/1/Actor_10/...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/raw/emotional-speech-audio/1/Actor_10/...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/raw/emotional-speech-audio/1/Actor_10/...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  modality  vocal_channel  \\\n",
       "0  ../data/raw/emotional-speech-audio/1/Actor_10/...         3              1   \n",
       "1  ../data/raw/emotional-speech-audio/1/Actor_10/...         3              1   \n",
       "2  ../data/raw/emotional-speech-audio/1/Actor_10/...         3              1   \n",
       "\n",
       "   emotion  emontion_intensity  statement  repetition  actor  gender  \n",
       "0        8                   1          2           2      2  female  \n",
       "1        6                   2          2           2      2  female  \n",
       "2        5                   1          1           1      1    male  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>modality</th>\n",
       "      <th>vocal_channel</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emontion_intensity</th>\n",
       "      <th>statement</th>\n",
       "      <th>repetition</th>\n",
       "      <th>actor</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>../data/raw/emotional-speech-audio/1/Actor_10/...</td>\n",
       "      <td>audio-only</td>\n",
       "      <td>speech</td>\n",
       "      <td>calm</td>\n",
       "      <td>strong</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>2nd repetition</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>../data/raw/emotional-speech-audio/1/Actor_09/...</td>\n",
       "      <td>audio-only</td>\n",
       "      <td>speech</td>\n",
       "      <td>disgust</td>\n",
       "      <td>normal</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>2nd repetition</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>../data/raw/emotional-speech-audio/1/Actor_20/...</td>\n",
       "      <td>audio-only</td>\n",
       "      <td>speech</td>\n",
       "      <td>calm</td>\n",
       "      <td>normal</td>\n",
       "      <td>Dogs are sitting by the door</td>\n",
       "      <td>2nd repetition</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filename    modality  \\\n",
       "34   ../data/raw/emotional-speech-audio/1/Actor_10/...  audio-only   \n",
       "247  ../data/raw/emotional-speech-audio/1/Actor_09/...  audio-only   \n",
       "328  ../data/raw/emotional-speech-audio/1/Actor_20/...  audio-only   \n",
       "\n",
       "    vocal_channel  emotion emontion_intensity                     statement  \\\n",
       "34         speech     calm             strong  Kids are talking by the door   \n",
       "247        speech  disgust             normal  Kids are talking by the door   \n",
       "328        speech     calm             normal  Dogs are sitting by the door   \n",
       "\n",
       "         repetition  actor  gender  \n",
       "34   2nd repetition      2  female  \n",
       "247  2nd repetition      2  female  \n",
       "328  2nd repetition      2  female  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modality_map = {1: \"full-AV\", 2: \"video-only\", 3: \"audio-only\"}\n",
    "vocal_channel_map = {1: \"speech\", 2: \"song\"}\n",
    "emotion_map = {1: \"neutral\", 2: \"calm\", 3: \"happy\", 4: \"sad\", 5: \"angry\", 6: \"fearful\", 7: \"disgust\", 8: \"surprised\"}\n",
    "emotion_intensity_map = {1: \"normal\", 2: \"strong\"}\n",
    "statement_map = {1: \"Kids are talking by the door\", 2: \"Dogs are sitting by the door\"}\n",
    "repetition_map = {1: \"1st repetition\", 2: \"2nd repetition\"}\n",
    "\n",
    "df['modality'] = df['modality'].map(modality_map)\n",
    "df['vocal_channel'] = df['vocal_channel'].map(vocal_channel_map)\n",
    "df['emotion'] = df['emotion'].map(emotion_map)\n",
    "df['emontion_intensity'] = df['emontion_intensity'].map(emotion_intensity_map)\n",
    "df['statement'] = df['statement'].map(statement_map)\n",
    "df['repetition'] = df['repetition'].map(repetition_map)\n",
    "\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../data/processed/audio_features.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
